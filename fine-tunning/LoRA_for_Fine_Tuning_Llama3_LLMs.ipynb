{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSvPp32SeCtaBks0nUsrgo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31c42f9fa8b640a6a4488e0ee9d6203b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08e9f84f51c14f8985a6b5059df585c4",
              "IPY_MODEL_378bdfc9d1b444aa935631a2bbe99996",
              "IPY_MODEL_67017b6e8a03422da69ce939c3761d70"
            ],
            "layout": "IPY_MODEL_3a102c9e22fb40b5950fd45f90be73a0"
          }
        },
        "08e9f84f51c14f8985a6b5059df585c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f29592443140d98893a76e5dc2fe12",
            "placeholder": "​",
            "style": "IPY_MODEL_bed4c370ddac49ed849bd3fb40053823",
            "value": "Map: 100%"
          }
        },
        "378bdfc9d1b444aa935631a2bbe99996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4084f353ad74bd8b838a70dd1c2e408",
            "max": 23993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2a935232c784e9990c0cdc17a1078de",
            "value": 23993
          }
        },
        "67017b6e8a03422da69ce939c3761d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_463f497ebf334721ab0bb1237da85057",
            "placeholder": "​",
            "style": "IPY_MODEL_ae43cb4c6a0f4f30b8184336ac373aa0",
            "value": " 23993/23993 [00:01&lt;00:00, 15011.74 examples/s]"
          }
        },
        "3a102c9e22fb40b5950fd45f90be73a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f29592443140d98893a76e5dc2fe12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed4c370ddac49ed849bd3fb40053823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4084f353ad74bd8b838a70dd1c2e408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a935232c784e9990c0cdc17a1078de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "463f497ebf334721ab0bb1237da85057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae43cb4c6a0f4f30b8184336ac373aa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelpivetta/tech-challenge-fase3/blob/main/LoRA%20for%20Fine-Tuning%20Llama3%20LLMs-Revisado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets peft trl bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDcW9MKsseOk",
        "outputId": "b8214e27-9b05-44b2-9d7f-948e0e398040"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.33.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.4)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.8.0)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0h3CEjbXqUwF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, pipeline, logging\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n",
        "\n",
        "base_model_name = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
        "amazon_products_dataset = \"ckandemir/amazon-products\"\n",
        "new_model =\"llama-1.1B-chat-amazon-products\"\n",
        "\n",
        "dataset = load_dataset(amazon_products_dataset, split=\"train\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token # pad sequences\n",
        "tokenizer.padding_side = \"right\" # right pad sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "prompt = \"Describe the product Hot Wheels 2019 Advent Calendar Vehicles.\"\n",
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100\n",
        ")\n",
        "result = pipe(f\"{prompt}\")\n",
        "print(result[0][\"generated_text\"])\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCspt3K8uHny",
        "outputId": "065f6457-25cb-4ab7-9dfb-586331e4af8e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Describe the product Hot Wheels 2019 Advent Calendar Vehicles.\n",
            "The 2019 Hot Wheels Advent Calendar is a 36-piece set of 1:64 scale die-cast cars. The set includes 12 cars, each with a different theme. The cars are all based on the 2019 Hot Wheels lineup, and include cars from the 2019 Monster Jam, Monster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LoRA\n",
        "peft_params = LoraConfig(\n",
        "    lora_alpha=16, # multiplier of Lora outpul when its added to the full forward output\n",
        "    lora_dropout=0.1, # with a probability of 10$ it will set random Lora output to 0\n",
        "    r=32, # rank of Lora so matrices will have either LHS or RHS dimension of 64\n",
        "    bias=\"none\", # no bias term\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "training_params = TrainingArguments(output_dir='./results',\n",
        "    num_train_epochs=3, # One pass over the dataset\n",
        "    per_device_train_batch_size=2, # mbs=1\n",
        "    gradient_accumulation_steps=16, # effective batch size 16*2\n",
        "    optim=\"adamw_torch\",\n",
        "    save_steps=200, # checkpoint every 100 steps\n",
        "    logging_steps=100,\n",
        "    learning_rate=3e-4, # step size in the optimizer update\n",
        "    weight_decay=0.001,\n",
        "    fp16=True, # 16 bit\n",
        "    bf16=False, # not supported on V100\n",
        "    max_grad_norm=0.3, # gradient clipping improves convergence\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03, # learning rate warmup\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"cosine\", #cosine lr scheduler\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_params, # parameter efficient fine tuning AKA Lora\n",
        "    dataset_text_field=\"Description\",\n",
        "    max_seq_length=128,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_params,\n",
        "    packing=False\n",
        ")\n",
        "\n",
        "import gc # garbage collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache() #clean cache\n",
        "\n",
        "trainer.train() #train the model\n",
        "trainer.model.save_pretrained(new_model)\n",
        "trainer.tokenizer.save_pretrained(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728,
          "referenced_widgets": [
            "31c42f9fa8b640a6a4488e0ee9d6203b",
            "08e9f84f51c14f8985a6b5059df585c4",
            "378bdfc9d1b444aa935631a2bbe99996",
            "67017b6e8a03422da69ce939c3761d70",
            "3a102c9e22fb40b5950fd45f90be73a0",
            "73f29592443140d98893a76e5dc2fe12",
            "bed4c370ddac49ed849bd3fb40053823",
            "f4084f353ad74bd8b838a70dd1c2e408",
            "a2a935232c784e9990c0cdc17a1078de",
            "463f497ebf334721ab0bb1237da85057",
            "ae43cb4c6a0f4f30b8184336ac373aa0"
          ]
        },
        "id": "g3uaFlJjvYPu",
        "outputId": "7cd57067-3c66-4f19-808e-5a357b956d04"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23993 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31c42f9fa8b640a6a4488e0ee9d6203b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 3.4557, 'grad_norm': 4.175568103790283, 'learning_rate': 0.0003997871820746685, 'epoch': 0.13336667500208385}\n",
            "{'loss': 3.096, 'grad_norm': 3.4048638343811035, 'learning_rate': 0.0003963890460321148, 'epoch': 0.2667333500041677}\n",
            "{'loss': 3.0291, 'grad_norm': 3.191901922225952, 'learning_rate': 0.00038891569880299245, 'epoch': 0.4001000250062516}\n",
            "{'loss': 2.9489, 'grad_norm': 2.847163200378418, 'learning_rate': 0.00037765484607478077, 'epoch': 0.5334667000083354}\n",
            "{'loss': 2.9003, 'grad_norm': 2.607309103012085, 'learning_rate': 0.0003627807660464467, 'epoch': 0.6668333750104193}\n",
            "{'loss': 2.8526, 'grad_norm': 2.3783931732177734, 'learning_rate': 0.0003443966111625041, 'epoch': 0.8002000500125032}\n",
            "{'loss': 2.7885, 'grad_norm': 2.2725889682769775, 'learning_rate': 0.000323016124777385, 'epoch': 0.9335667250145869}\n",
            "{'loss': 2.6918, 'grad_norm': 1.876269817352295, 'learning_rate': 0.00029908296705977654, 'epoch': 1.0669334000166708}\n",
            "{'loss': 2.63, 'grad_norm': 1.8575735092163086, 'learning_rate': 0.0002730937679085009, 'epoch': 1.2003000750187547}\n",
            "{'loss': 2.5624, 'grad_norm': 1.9878522157669067, 'learning_rate': 0.000245587821531922, 'epoch': 1.3336667500208386}\n",
            "{'loss': 2.5118, 'grad_norm': 1.877140760421753, 'learning_rate': 0.00021713589571284504, 'epoch': 1.4670334250229224}\n",
            "{'loss': 2.4986, 'grad_norm': 2.094419479370117, 'learning_rate': 0.00018832838797455329, 'epoch': 1.600400100025006}\n",
            "{'loss': 2.4555, 'grad_norm': 2.02018666267395, 'learning_rate': 0.00015976307441588816, 'epoch': 1.7337667750270902}\n",
            "{'loss': 2.4013, 'grad_norm': 2.092698812484741, 'learning_rate': 0.00013203270543568317, 'epoch': 1.8671334500291739}\n",
            "{'loss': 2.3986, 'grad_norm': 2.1370699405670166, 'learning_rate': 0.00010571270574401802, 'epoch': 2.000500125031258}\n",
            "{'loss': 2.2444, 'grad_norm': 1.6302359104156494, 'learning_rate': 8.134923389372952e-05, 'epoch': 2.1338668000333416}\n",
            "{'loss': 2.2657, 'grad_norm': 1.6691572666168213, 'learning_rate': 5.944784910532406e-05, 'epoch': 2.2672334750354257}\n",
            "{'loss': 2.2445, 'grad_norm': 1.9048242568969727, 'learning_rate': 4.046302055666209e-05, 'epoch': 2.4006001500375094}\n",
            "{'loss': 2.258, 'grad_norm': 1.6914275884628296, 'learning_rate': 2.4788696827054826e-05, 'epoch': 2.5339668250395935}\n",
            "{'loss': 2.2102, 'grad_norm': 1.667373538017273, 'learning_rate': 1.2750131186454539e-05, 'epoch': 2.667333500041677}\n",
            "{'loss': 2.2139, 'grad_norm': 1.7536009550094604, 'learning_rate': 4.597132360755252e-06, 'epoch': 2.800700175043761}\n",
            "{'loss': 2.2131, 'grad_norm': 1.6167761087417603, 'learning_rate': 4.988808245805166e-07, 'epoch': 2.934066850045845}\n",
            "{'train_runtime': 3792.8976, 'train_samples_per_second': 18.977, 'train_steps_per_second': 0.592, 'train_loss': 2.5781796960020045, 'epoch': 2.996749187296824}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('llama-1.1B-chat-amazon-products/tokenizer_config.json',\n",
              " 'llama-1.1B-chat-amazon-products/special_tokens_map.json',\n",
              " 'llama-1.1B-chat-amazon-products/tokenizer.model',\n",
              " 'llama-1.1B-chat-amazon-products/added_tokens.json',\n",
              " 'llama-1.1B-chat-amazon-products/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Describe the product Hot Wheels 2019 Advent Calendar Vehicles.\"\n",
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=100\n",
        ")\n",
        "result_fine_tuning = pipe(f'{prompt}')\n",
        "print(result_fine_tuning[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaqNUIzZpWt-",
        "outputId": "bd3d9954-3c6b-4973-ab8a-beed74e6d6cf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Describe the product Hot Wheels 2019 Advent Calendar Vehicles.\n",
            "The Hot Wheels 2019 Advent Calendar Vehicles is a great gift for kids aged 8 and up. The Hot Wheels 2019 Advent Calendar Vehicles is a great gift for kids aged 8 and up. The Hot Wheels 2019 Advent Calendar Vehicles is a great gift for kids aged 8 and up\n"
          ]
        }
      ]
    }
  ]
}